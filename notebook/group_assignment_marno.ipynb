{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying custom feature engineering...\n",
      "\n",
      "Dataset after feature engineering: (1359, 25)\n",
      "Features: ['Brand', 'Battery capacity (mAh)', 'Screen size (inches)', 'Touchscreen', 'Processor', 'Internal storage (GB)', 'Rear camera', 'Front camera', 'Wi-Fi', 'Bluetooth', 'GPS', 'Number of SIMs', '3G', '4G/ LTE', 'price_range', 'screen_area', 'resolution_total', 'pixel_density', 'RAM_GB', 'performance_score', 'camera_score', 'connectivity_score', 'brand_avg_price', 'storage_ram_ratio', 'OS_category']\n",
      "\n",
      "Price Range Categories: ['budget', 'high_mid', 'low_mid', 'premium']\n",
      "Distribution of price ranges:\n",
      "budget: 429 phones (31.6%)\n",
      "high_mid: 244 phones (18.0%)\n",
      "low_mid: 526 phones (38.7%)\n",
      "premium: 160 phones (11.8%)\n",
      "\n",
      "Performing Grid Search for XGBoost parameters...\n",
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "\n",
      "Grid Search completed in 37.08 seconds.\n",
      "Best parameters: {'classifier__colsample_bytree': 0.8, 'classifier__learning_rate': 0.05, 'classifier__max_depth': 3, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 200, 'classifier__subsample': 0.8}\n",
      "Best cross-validation score: 0.6854\n",
      "\n",
      "Test Accuracy with optimal parameters: 0.6618\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      budget       0.73      0.70      0.71        86\n",
      "    high_mid       0.58      0.43      0.49        49\n",
      "     low_mid       0.60      0.71      0.66       105\n",
      "     premium       0.80      0.75      0.77        32\n",
      "\n",
      "    accuracy                           0.66       272\n",
      "   macro avg       0.68      0.65      0.66       272\n",
      "weighted avg       0.66      0.66      0.66       272\n",
      "\n",
      "\n",
      "Top 15 Features for Price Range Prediction:\n",
      "                  Feature  Importance\n",
      "20        brand_avg_price    0.075157\n",
      "14       resolution_total    0.052773\n",
      "15          pixel_density    0.035637\n",
      "5             Rear camera    0.035572\n",
      "16                 RAM_GB    0.034954\n",
      "25            Brand_Apple    0.034701\n",
      "18           camera_score    0.031919\n",
      "4   Internal storage (GB)    0.029397\n",
      "84             Brand_Vivo    0.023324\n",
      "17      performance_score    0.022394\n",
      "3               Processor    0.020706\n",
      "30       Brand_BlackBerry    0.019294\n",
      "6            Front camera    0.018271\n",
      "13            screen_area    0.018180\n",
      "1    Screen size (inches)    0.018149\n",
      "\n",
      "Optimized model saved as 'xgboost_custom_features_model.pkl'\n",
      "\n",
      "Accuracy by Original Price Range:\n",
      "Premium (15K-30K): 0.5135 (19/37)\n",
      "Mid-range (5K-15K): 0.6466 (86/133)\n",
      "Budget (<5K): 0.6977 (60/86)\n",
      "Flagship (>30K): 0.9375 (15/16)\n",
      "\n",
      "Example prediction with custom feature-engineered model:\n",
      "Sample Phone Brand: Motorola\n",
      "Screen Size: 5.7 inches\n",
      "Internal Storage: 16.0 GB\n",
      "Processor Cores: 6\n",
      "Actual Price: ₹20999\n",
      "\n",
      "Predicted Price Range: premium\n",
      "\n",
      "Probability Distribution:\n",
      "  budget: 0.0096\n",
      "  high_mid: 0.3418\n",
      "  low_mid: 0.1359\n",
      "  premium: 0.5127\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import xgboost as xgb\n",
    "import time\n",
    "\n",
    "# Custom feature engineering function\n",
    "def feature_engineering(df):\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    price_ranges = [0, 5000, 10000, 20000, float('inf')]\n",
    "    labels = ['budget', 'low_mid', 'high_mid', 'premium']\n",
    "    df_processed['price_range'] = pd.cut(df_processed['Price'], bins=price_ranges, labels=labels, right=False)\n",
    "    \n",
    "    df_processed['screen_area'] = df_processed['Screen size (inches)'] ** 2\n",
    "    df_processed['resolution_total'] = df_processed['Resolution x'] * df_processed['Resolution y']\n",
    "    df_processed['pixel_density'] = np.sqrt(df_processed['resolution_total']) / df_processed['Screen size (inches)']\n",
    "    \n",
    "    df_processed['RAM_GB'] = df_processed['RAM (MB)'] / 1000\n",
    "    \n",
    "    df_processed['performance_score'] = df_processed['Processor'] * df_processed['RAM_GB']\n",
    "    \n",
    "    df_processed['camera_score'] = df_processed['Rear camera'] + 0.5 * df_processed['Front camera']\n",
    "    \n",
    "    binary_features = ['Touchscreen', 'Wi-Fi', 'Bluetooth', 'GPS', '3G', '4G/ LTE']\n",
    "    for feature in binary_features:\n",
    "        df_processed[feature] = df_processed[feature].map({'Yes': 1, 'No': 0})\n",
    "    \n",
    "    connectivity_features = ['Wi-Fi', 'Bluetooth', 'GPS', '3G', '4G/ LTE']\n",
    "    df_processed['connectivity_score'] = df_processed[connectivity_features].sum(axis=1)\n",
    "    \n",
    "    brand_avg_price = df.groupby('Brand')['Price'].mean().reset_index()\n",
    "    brand_avg_price.columns = ['Brand', 'brand_avg_price']\n",
    "    df_processed = pd.merge(df_processed, brand_avg_price, on='Brand', how='left')\n",
    "    \n",
    "    df_processed['storage_ram_ratio'] = df_processed['Internal storage (GB)'] / df_processed['RAM_GB']\n",
    "    df_processed['OS_category'] = df_processed['Operating system'].map(\n",
    "        lambda x: 'iOS' if x == 'iOS' else ('Android' if x == 'Android' else 'Other')\n",
    "    )\n",
    "    \n",
    "    drop_cols = ['Unnamed: 0', 'Name', 'Model', 'Resolution x', 'Resolution y', \n",
    "                'RAM (MB)', 'Price', 'Operating system'] \n",
    "    \n",
    "    drop_cols = [col for col in drop_cols if col in df_processed.columns]\n",
    "    df_processed = df_processed.drop(columns=drop_cols)\n",
    "    numeric_cols = df_processed.select_dtypes(include=['int64', 'float64']).columns\n",
    "    df_processed[numeric_cols] = df_processed[numeric_cols].fillna(0)\n",
    "    \n",
    "    cat_cols = df_processed.select_dtypes(include=['object', 'category']).columns\n",
    "    for col in cat_cols:\n",
    "        if col != 'price_range':  # Don't modify the target variable\n",
    "            most_frequent = df_processed[col].mode()[0]\n",
    "            df_processed[col] = df_processed[col].fillna(most_frequent)\n",
    "    \n",
    "    if 'storage_ram_ratio' in df_processed.columns:\n",
    "        df_processed['storage_ram_ratio'] = df_processed['storage_ram_ratio'].replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "    return df_processed\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('/Users/marno/Documents/Coding/MachineLearningGroupProject_TXB_8/data/ndtv_data_final.csv')\n",
    "\n",
    "# Process data using custom feature engineering\n",
    "print(\"Applying custom feature engineering...\")\n",
    "df_processed = feature_engineering(df)\n",
    "\n",
    "# Show the new features created\n",
    "print(f\"\\nDataset after feature engineering: {df_processed.shape}\")\n",
    "print(f\"Features: {df_processed.columns.tolist()}\")\n",
    "\n",
    "# Prepare data for modeling\n",
    "X = df_processed.drop(columns=['price_range'])\n",
    "y = df_processed['price_range']\n",
    "\n",
    "# Map categorical target to numerical values for modeling\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "price_range_names = label_encoder.classes_.tolist()\n",
    "\n",
    "print(f\"\\nPrice Range Categories: {price_range_names}\")\n",
    "print(\"Distribution of price ranges:\")\n",
    "for i, category in enumerate(price_range_names):\n",
    "    count = (y_encoded == i).sum()\n",
    "    percentage = count / len(y_encoded) * 100\n",
    "    print(f\"{category}: {count} phones ({percentage:.1f}%)\")\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "\n",
    "# Get numeric and categorical columns\n",
    "numeric_columns = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_columns = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# Create preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_columns),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Create pipeline with XGBoost\n",
    "xgb_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', xgb.XGBClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Define the parameter grid for XGBoost\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__max_depth': [3, 5, 7],\n",
    "    'classifier__learning_rate': [0.05, 0.1, 0.2],\n",
    "    'classifier__subsample': [0.8, 1.0],\n",
    "    'classifier__colsample_bytree': [0.8, 1.0],\n",
    "    'classifier__min_child_weight': [1, 3]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV object\n",
    "print(\"\\nPerforming Grid Search for XGBoost parameters...\")\n",
    "start_time = time.time()\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(f\"\\nGrid Search completed in {time.time() - start_time:.2f} seconds.\")\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nTest Accuracy with optimal parameters: {accuracy:.4f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=price_range_names))\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=price_range_names, \n",
    "            yticklabels=price_range_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - XGBoost with Custom Features')\n",
    "plt.tight_layout()\n",
    "plt.savefig('xgboost_custom_features_confusion_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "# Feature importance analysis\n",
    "model = best_model.named_steps['classifier']\n",
    "preprocessor = best_model.named_steps['preprocessor']\n",
    "\n",
    "# Get feature names after preprocessing (handling one-hot encoding)\n",
    "ohe = preprocessor.transformers_[1][1]\n",
    "if len(categorical_columns) > 0:\n",
    "    categorical_feature_names = ohe.get_feature_names_out(categorical_columns).tolist()\n",
    "    all_feature_names = numeric_columns + categorical_feature_names\n",
    "else:\n",
    "    all_feature_names = numeric_columns\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "# Create DataFrame for feature importance\n",
    "feature_imp_df = pd.DataFrame({\n",
    "    'Feature': all_feature_names[:len(feature_importances)],\n",
    "    'Importance': feature_importances\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# Display top 15 features\n",
    "print(\"\\nTop 15 Features for Price Range Prediction:\")\n",
    "print(feature_imp_df.head(15))\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_imp_df.head(15))\n",
    "plt.title('Top 15 Features for Price Range Prediction - Custom Engineered Features')\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance_custom_features.png')\n",
    "plt.close()\n",
    "\n",
    "# Save the model\n",
    "import joblib\n",
    "joblib.dump(best_model, 'xgboost_custom_features_model.pkl')\n",
    "\n",
    "print(\"\\nOptimized model saved as 'xgboost_custom_features_model.pkl'\")\n",
    "\n",
    "# Compare results with original price categories\n",
    "# For reference, create the original 4-category price ranges\n",
    "df['original_price_range'] = pd.cut(\n",
    "    df['Price'], \n",
    "    bins=[0, 5000, 15000, 30000, float('inf')], \n",
    "    labels=['Budget (<5K)', 'Mid-range (5K-15K)', 'Premium (15K-30K)', 'Flagship (>30K)'],\n",
    "    right=False\n",
    ")\n",
    "\n",
    "# Map our predictions back to the original dataframe IDs\n",
    "test_indices = X_test.index\n",
    "df_test = df.loc[test_indices].copy()\n",
    "df_test['predicted_category'] = label_encoder.inverse_transform(y_pred)\n",
    "df_test['actual_category'] = label_encoder.inverse_transform(y_test)\n",
    "\n",
    "# Calculate accuracy by original price range\n",
    "original_ranges = df_test['original_price_range'].unique()\n",
    "print(\"\\nAccuracy by Original Price Range:\")\n",
    "for orig_range in original_ranges:\n",
    "    subset = df_test[df_test['original_price_range'] == orig_range]\n",
    "    correct = (subset['predicted_category'] == subset['actual_category']).sum()\n",
    "    accuracy_range = correct / len(subset) if len(subset) > 0 else 0\n",
    "    print(f\"{orig_range}: {accuracy_range:.4f} ({correct}/{len(subset)})\")\n",
    "\n",
    "# Create a function for predicting with the new model\n",
    "def predict_price_range(phone_features, model, label_encoder):\n",
    "    \"\"\"\n",
    "    Predict price range for a new phone using the custom feature-engineered model\n",
    "    \n",
    "    Parameters:\n",
    "    phone_features: Dictionary with original phone features\n",
    "    model: Trained model pipeline\n",
    "    label_encoder: Encoder used for price range categories\n",
    "    \n",
    "    Returns:\n",
    "    Predicted price range and probabilities\n",
    "    \"\"\"\n",
    "    # Create a DataFrame with the phone features\n",
    "    phone_df = pd.DataFrame([phone_features])\n",
    "    \n",
    "    # Apply the same feature engineering\n",
    "    # We need a temporary Price column to use the feature engineering function\n",
    "    if 'Price' not in phone_df.columns:\n",
    "        phone_df['Price'] = 0  # Temporary value, will be dropped\n",
    "    \n",
    "    processed_df = feature_engineering(phone_df)\n",
    "    \n",
    "    # Drop the target column if it exists\n",
    "    if 'price_range' in processed_df.columns:\n",
    "        processed_df = processed_df.drop(columns=['price_range'])\n",
    "    \n",
    "    # Make prediction\n",
    "    predicted_class = model.predict(processed_df)[0]\n",
    "    predicted_probas = model.predict_proba(processed_df)[0]\n",
    "    \n",
    "    # Get predicted category name\n",
    "    predicted_category = label_encoder.inverse_transform([predicted_class])[0]\n",
    "    \n",
    "    # Create probability dictionary\n",
    "    probability_dict = {cat: prob for cat, prob in zip(label_encoder.classes_, predicted_probas)}\n",
    "    \n",
    "    return predicted_category, probability_dict\n",
    "\n",
    "# Test prediction with a sample phone\n",
    "print(\"\\nExample prediction with custom feature-engineered model:\")\n",
    "sample_phone = df.iloc[X_test.index[0]].to_dict()\n",
    "print(f\"Sample Phone Brand: {sample_phone.get('Brand', 'Unknown')}\")\n",
    "print(f\"Screen Size: {sample_phone.get('Screen size (inches)', 0)} inches\")\n",
    "print(f\"Internal Storage: {sample_phone.get('Internal storage (GB)', 0)} GB\")\n",
    "print(f\"Processor Cores: {sample_phone.get('Processor', 0)}\")\n",
    "print(f\"Actual Price: ₹{sample_phone.get('Price', 0)}\")\n",
    "\n",
    "predicted_category, probabilities = predict_price_range(sample_phone, best_model, label_encoder)\n",
    "print(f\"\\nPredicted Price Range: {predicted_category}\")\n",
    "print(\"\\nProbability Distribution:\")\n",
    "for category, probability in probabilities.items():\n",
    "    print(f\"  {category}: {probability:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
